input_file: results/aeval+Loopy/ranking_results_PmtTpl_qwen3max/aeval/c_bench_term/CookSeeZuleger-TACAS2013-Fig7b-true-termination_true-no-overflow_inv_ranking.yml
source_file: CookSeeZuleger-TACAS2013-Fig7b-true-termination_true-no-overflow_inv_ranking.yml
task: svmranker
svmranker_result:
- loop_id: 1
  template_type: lmulti
  template_depth: 3
  svm_mode: lmulti
  status: NONTERM
  ranking_function: <NestedTemplate.NestedTemplate object at 0x7e65ed837d00>
  ranking_functions:
  - <NestedTemplate.NestedTemplate object at 0x7e65ed837d00>
  input_code_source: boogie_path
  input_code_path: /home/clexma/Desktop/fox3/TermDB/TerminationDatabase/Data_boogie/aeval/c_bench_term/CookSeeZuleger-TACAS2013-Fig7b-true-termination_true-no-overflow.bpl
  input_boogie_path: /home/clexma/Desktop/fox3/TermDB/TerminationDatabase/Data_boogie/aeval/c_bench_term/CookSeeZuleger-TACAS2013-Fig7b-true-termination_true-no-overflow.bpl
